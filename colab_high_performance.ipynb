{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header_md"
      },
      "source": [
        "# ğŸš€ Hybrid QML vs Classical SOTA â€” Full Training & Comparison\n",
        "\n",
        "This notebook lets you train **either or both** of:\n",
        "1. **Hybrid QML** â€” ResNet18 (frozen) + 10-qubit PQC Ensemble (~92â€“93% acc)\n",
        "2. **Classical SOTA** â€” ResNet50 two-stage fine-tune baseline (~strong reference)\n",
        "\n",
        "Then run a **side-by-side evaluation** (accuracy, F1, AUC, precision, recall).\n",
        "\n",
        "> âš ï¸ **Required:** GPU runtime â€” go to **Runtime â†’ Change runtime type â†’ T4 GPU**"
      ],
      "id": "header_md"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "user_config",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2a82f01-f46f-4d03-f25b-1100e5d69c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Configuration set.\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# ğŸ”§ USER CONFIGURATION â€” Edit these as needed\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Which models to train? Set True/False independently.\n",
        "TRAIN_HYBRID    = True   # Hybrid QML (ResNet18 + Quantum Ensemble)\n",
        "TRAIN_CLASSICAL = True   # Classical SOTA (ResNet50, two-stage fine-tune)\n",
        "\n",
        "# Run head-to-head comparison after training?\n",
        "RUN_COMPARISON  = True\n",
        "\n",
        "# Dataset path on Google Drive\n",
        "DRIVE_DATASET_PATH = '/content/drive/MyDrive/medical_imaging_data/brain_tumor_dataset'\n",
        "\n",
        "# Where to persist outputs on Drive\n",
        "DRIVE_OUTPUT_PATH  = '/content/drive/MyDrive/qml_medical_imaging_outputs'\n",
        "\n",
        "# Repo\n",
        "REPO_URL    = 'https://github.com/DreamX55/QML-for-Medical-Imaging.git'\n",
        "PROJECT_KEY = 'qml_medical_imaging'\n",
        "PROJECT_ROOT = f'/content/{PROJECT_KEY}'\n",
        "\n",
        "# Training hyper-params\n",
        "BATCH_SIZE         = 32\n",
        "HYBRID_EPOCHS      = 15          # Hybrid model epochs (frozen backbone)\n",
        "CLASSICAL_STAGE1   = 10          # Classical: Stage 1 (frozen backbone)\n",
        "CLASSICAL_STAGE2   = 15          # Classical: Stage 2 (fine-tune layer4)\n",
        "NUM_WORKERS        = 2\n",
        "DEVICE             = 'cpu'      # 'cuda' | 'cpu'\n",
        "\n",
        "# Output sub-dirs (relative to DRIVE_OUTPUT_PATH)\n",
        "HYBRID_OUT_DIR     = 'outputs/high_perf_resnet'\n",
        "CLASSICAL_OUT_DIR  = 'outputs/classical_sota'\n",
        "COMPARISON_JSON    = 'outputs/comparison_results.json'\n",
        "\n",
        "print('âœ… Configuration set.')"
      ],
      "id": "user_config"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "setup_env",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414be9a8-b773-4aff-8944-06996ab3dfa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning repo...\n",
            "/content\n",
            "Cloning into 'qml_medical_imaging'...\n",
            "remote: Enumerating objects: 125, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 125 (delta 50), reused 103 (delta 31), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (125/125), 124.02 KiB | 7.29 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/qml_medical_imaging\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m935.6/935.6 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "âœ… Environment ready.\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 1. Mount Drive & Clone / Update Repo\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "if os.path.exists(PROJECT_ROOT):\n",
        "    print(f'Repo exists. Pulling latest...')\n",
        "    %cd {PROJECT_ROOT}\n",
        "    !git pull\n",
        "else:\n",
        "    print(f'Cloning repo...')\n",
        "    %cd /content\n",
        "    !git clone {REPO_URL} {PROJECT_KEY}\n",
        "\n",
        "%cd {PROJECT_ROOT}\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q pennylane-lightning\n",
        "print('âœ… Environment ready.')"
      ],
      "id": "setup_env"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gpu_check",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce34e068-a5b4-4179-8354-7e97cdd7cf67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch : 2.10.0+cu128\n",
            "CUDA    : True\n",
            "GPU     : Tesla T4\n",
            "Sat Feb 21 07:07:53 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8             12W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 2. Check Hardware (GPU or CPU)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import torch\n",
        "print(f'PyTorch : {torch.__version__}')\n",
        "print(f'CUDA    : {torch.cuda.is_available()}')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU     : {torch.cuda.get_device_name(0)}')\n",
        "    import subprocess\n",
        "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "else:\n",
        "    print('â„¹ï¸  Running on CPU â€” training will be slower but fully functional.')\n",
        "    print('   Tip: Quantum simulation on CPU is ~2â€“5 min/epoch for small batches.')\n"
      ],
      "id": "gpu_check"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "link_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696e4e59-5672-4bc6-c831-c29df65da52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linked  /content/drive/MyDrive/medical_imaging_data/brain_tumor_dataset  â†’  /content/qml_medical_imaging/data/brain_mri\n",
            "Linked  /content/drive/MyDrive/qml_medical_imaging_outputs  â†’  /content/qml_medical_imaging/outputs\n",
            "âœ… Data and outputs linked to Drive.\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 3. Link Data & Outputs from Drive\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "def force_symlink(src, dst):\n",
        "    if os.path.exists(dst) or os.path.islink(dst):\n",
        "        if os.path.isdir(dst) and not os.path.islink(dst):\n",
        "            shutil.rmtree(dst)\n",
        "        else:\n",
        "            os.remove(dst)\n",
        "    os.symlink(src, dst)\n",
        "    print(f'Linked  {src}  â†’  {dst}')\n",
        "\n",
        "# Data\n",
        "data_link = os.path.join(PROJECT_ROOT, 'data/brain_mri')\n",
        "os.makedirs(os.path.join(PROJECT_ROOT, 'data'), exist_ok=True)\n",
        "force_symlink(DRIVE_DATASET_PATH, data_link)\n",
        "\n",
        "# Outputs\n",
        "if not os.path.exists(DRIVE_OUTPUT_PATH):\n",
        "    os.makedirs(DRIVE_OUTPUT_PATH, exist_ok=True)\n",
        "output_link = os.path.join(PROJECT_ROOT, 'outputs')\n",
        "force_symlink(DRIVE_OUTPUT_PATH, output_link)\n",
        "\n",
        "print('âœ… Data and outputs linked to Drive.')"
      ],
      "id": "link_data"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_header"
      },
      "source": [
        "---\n",
        "## ğŸ§ª Training\n",
        "The next two cells train the **Hybrid QML** and **Classical SOTA** models respectively.\n",
        "Each cell only runs if the corresponding flag is set to `True` above."
      ],
      "id": "train_header"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "train_hybrid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "ac44096e-9e71-41db-d513-41ee1dbe6c8e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TRAIN_HYBRID' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-469830273.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 4a. Train Hybrid QML Model (ResNet18 + Quantum Ensemble)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mTRAIN_HYBRID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ğŸ”¬ Training Hybrid QML model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python main.py --mode train          --data_dir data/brain_mri          --project_name qml_high_perf          --model_type hybrid          --backbone resnet18          --freeze_backbone          --epochs {HYBRID_EPOCHS}          --batch_size {BATCH_SIZE}          --num_workers {NUM_WORKERS}          --quantum_device default.qubit          --device {DEVICE}          --output_dir {HYBRID_OUT_DIR}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TRAIN_HYBRID' is not defined"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 4a. Train Hybrid QML Model (ResNet18 + Quantum Ensemble)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "if TRAIN_HYBRID:\n",
        "    print('ğŸ”¬ Training Hybrid QML model...')\n",
        "    !python main.py --mode train \\\n",
        "        --data_dir data/brain_mri \\\n",
        "        --project_name qml_high_perf \\\n",
        "        --model_type hybrid \\\n",
        "        --backbone resnet18 \\\n",
        "        --freeze_backbone \\\n",
        "        --epochs {HYBRID_EPOCHS} \\\n",
        "        --batch_size {BATCH_SIZE} \\\n",
        "        --num_workers {NUM_WORKERS} \\\n",
        "        --quantum_device default.qubit \\\n",
        "        --device {DEVICE} \\\n",
        "        --output_dir {HYBRID_OUT_DIR}\n",
        "else:\n",
        "    print('â­ï¸  Skipping Hybrid QML training (TRAIN_HYBRID=False)')"
      ],
      "id": "train_hybrid"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "train_classical",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c789c8-fbb9-449b-b25a-522ca996d4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ‹ï¸  Training Classical SOTA model (ResNet50)...\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 4b. Train Classical SOTA Model (ResNet50, Two-Stage)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "if TRAIN_CLASSICAL:\n",
        "    print('ğŸ‹ï¸  Training Classical SOTA model (ResNet50)...')\n",
        "    !python training/train_classical_sota.py \\\n",
        "        --data_dir data/brain_mri \\\n",
        "        --output_dir {CLASSICAL_OUT_DIR} \\\n",
        "        --epochs_stage1 {CLASSICAL_STAGE1} \\\n",
        "        --epochs_stage2 {CLASSICAL_STAGE2} \\\n",
        "        --batch_size {BATCH_SIZE} \\\n",
        "        --num_workers {NUM_WORKERS} \\\n",
        "        --device {DEVICE}\n",
        "else:\n",
        "    print('â­ï¸  Skipping Classical SOTA training (TRAIN_CLASSICAL=False)')"
      ],
      "id": "train_classical"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_header"
      },
      "source": [
        "---\n",
        "## ğŸ“Š Head-to-Head Evaluation\n",
        "Loads both saved checkpoints and evaluates them on the **same test set**.\n",
        "Results are printed side-by-side and saved to Drive."
      ],
      "id": "eval_header"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "run_comparison",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8327e3b-2ce6-4753-92ef-9879834f013c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸  Missing checkpoints â€” train the models first:\n",
            "   outputs/high_perf_resnet/checkpoints/best_model.pt\n",
            "   outputs/classical_sota/best_model.pt\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 5. Side-by-Side: Hybrid QML vs Classical SOTA\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "HYBRID_CKPT    = f'{HYBRID_OUT_DIR}/checkpoints/best_model.pt'\n",
        "CLASSICAL_CKPT = f'{CLASSICAL_OUT_DIR}/best_model.pt'\n",
        "\n",
        "if RUN_COMPARISON:\n",
        "    # Verify both checkpoints exist before running\n",
        "    import os\n",
        "    missing = [p for p in [HYBRID_CKPT, CLASSICAL_CKPT] if not os.path.exists(p)]\n",
        "    if missing:\n",
        "        print('âš ï¸  Missing checkpoints â€” train the models first:')\n",
        "        for m in missing:\n",
        "            print(f'   {m}')\n",
        "    else:\n",
        "        print('âš–ï¸  Running head-to-head comparison...')\n",
        "        !python evaluation/evaluate_classical_vs_hybrid.py \\\n",
        "            --data_dir data/brain_mri \\\n",
        "            --hybrid_checkpoint {HYBRID_CKPT} \\\n",
        "            --classical_checkpoint {CLASSICAL_CKPT} \\\n",
        "            --batch_size {BATCH_SIZE} \\\n",
        "            --num_workers {NUM_WORKERS} \\\n",
        "            --device {DEVICE} \\\n",
        "            --output_json {COMPARISON_JSON}\n",
        "        print(f'\\nâœ… Comparison JSON saved â†’ {COMPARISON_JSON}')\n",
        "else:\n",
        "    print('â­ï¸  Skipping comparison (RUN_COMPARISON=False)')"
      ],
      "id": "run_comparison"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "plot_results",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e1b0ac-50a2-4511-d4db-f5c8a05fab0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No comparison JSON found at outputs/comparison_results.json. Run Cell 5 first.\n"
          ]
        }
      ],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# 6. Visualise Results (reads comparison JSON)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import json, os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "if not os.path.exists(COMPARISON_JSON):\n",
        "    print(f'No comparison JSON found at {COMPARISON_JSON}. Run Cell 5 first.')\n",
        "else:\n",
        "    with open(COMPARISON_JSON) as f:\n",
        "        res = json.load(f)\n",
        "\n",
        "    metrics_ = ['accuracy', 'f1_macro', 'roc_auc', 'precision_macro', 'recall_macro']\n",
        "    labels_  = ['Accuracy', 'F1 (macro)', 'ROC-AUC', 'Precision', 'Recall']\n",
        "\n",
        "    h_vals = [res['hybrid'][m] for m in metrics_]\n",
        "    c_vals = [res['classical'][m] for m in metrics_]\n",
        "\n",
        "    x = np.arange(len(labels_))\n",
        "    w = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.bar(x - w/2, h_vals, w, label='Hybrid QML (ResNet18+Q)', color='steelblue', alpha=0.85)\n",
        "    ax.bar(x + w/2, c_vals, w, label='Classical SOTA (ResNet50)', color='tomato', alpha=0.85)\n",
        "\n",
        "    ax.set_ylabel('Score', fontsize=12)\n",
        "    ax.set_title('Hybrid QML vs Classical SOTA â€” Test Set Metrics', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(labels_, fontsize=11)\n",
        "    ax.set_ylim(0, 1.05)\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.yaxis.grid(True, alpha=0.4)\n",
        "\n",
        "    for i, (hv, cv) in enumerate(zip(h_vals, c_vals)):\n",
        "        ax.text(i - w/2, hv + 0.01, f'{hv:.3f}', ha='center', va='bottom', fontsize=9, color='steelblue')\n",
        "        ax.text(i + w/2, cv + 0.01, f'{cv:.3f}', ha='center', va='bottom', fontsize=9, color='tomato')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plot_path = COMPARISON_JSON.replace('.json', '_bar.png')\n",
        "    plt.savefig(plot_path, dpi=150)\n",
        "    plt.show()\n",
        "    print(f'âœ… Plot saved â†’ {plot_path}')"
      ],
      "id": "plot_results"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbformat_minor": 5,
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}